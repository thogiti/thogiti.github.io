---
title: Understanding Erasure Coding - A Deep Dive into Mathematical Foundations
tags: Erasure-coding Ethereum Danksharding Scalability Product-Code algebraic-coding-theory Data-Extraction Data-Interpolation Missing-Value-Analysis Coefficient-Extraction Error-Correction Generalized-Reed-Solomon-Codes Reed-Solomon-Codes 
---

# Introduction

Imagine you’re part of a new decentralized blockchain aiming to store massive amounts of data on-chain—think NFT artwork, transaction histories, and user-generated archives. Each node in the network hosts only a slice of the total ledger. Some nodes go offline unexpectedly; others might be malicious. Directly replicating every byte multiple times is costly and slows down the entire blockchain.  
   
Meanwhile, losing data is not an option: if critical records vanish, the decentralized trust model breaks. How can you keep data *highly available* without drowning in storage costs?  

That’s where erasure coding shines—splitting your data into shards, each individually *unusable* if intercepted or lost, yet fully reconstructable if you can gather enough surviving pieces. This approach drastically lowers overhead compared to naive replication (like storing three or five copies of everything) and offers built-in security advantages because no single shard reveals your entire data.

## Motivation and Article Roadmap

This article provides a deep dive into how erasure coding works, explaining the linear algebra, finite field arithmetic, binary matrix optimizations and other Mathematical foundations behind it. By the end, you’ll see how blockchain projects, cloud services, and countless other data-centric platforms rely on mathematics to keep mission-critical data safe—while avoiding the heavy burden of repeated replicas.

We’ll cover:

- Erasure Coding Basics: Core definitions, highlighting why it outperforms straightforward replication.  
- Mathematical Foundations: From Cauchy matrices and matrix multiplication to decoding with submatrix inversions.  
- Finite Fields: How prime fields $GF(p)$ and extension fields $GF(2^n)$ empower exact, lossless arithmetic.  
- Binary Matrices: Translating field operations into high-speed XOR-based implementations.  
- Implementation Details: Pseudocode examples in Python, plus some practical tips on performance.  
- Challenges & Future Directions: The overhead of repair, quantum-era considerations, and beyond.

Let’s dive in.

---

# Erasure Coding Basics

## What Is an $[N, K]$ Erasure Code?
An $[N, K]$ erasure code transforms your original data into $N$ encoded pieces (shards), with these properties:

- Each shard is roughly $1/K$th the size of the original data (ignoring small overhead).  
- If you lose up to $N - K$ shards, you can still recover the original data from any K surviving shards.

This means you get tolerance to failures (up to $N - K$) without storing multiple full copies.

Here’s a diagram showing the conceptual flow:

```mermaid
flowchart LR
    A[Original Data] --> B[Split into K Data Chunks]
    B --> C[Encode into N Shards Matrix Mult]
    C -- Some shards lost --> D[Only K Shards Remain]
    D --> E[Decode Submatrix Inversion]
    E --> F[Reconstructed Data]
```

Let's understand what's going on in the above diagram. 
- We chunk the data into $K$ parts.  
- We multiply by an $N \times K$ encoder matrix to produce N shards.  
- Even if some shards vanish, as long as we have any $K$ shards, we can decode back to the original data.

## Why Is It Better Than Replication?

- Reduced Cost  
   - Replication: To tolerate $F$ failures, you need $F+1$ full copies (i.e., $(F+1) \times overhead$).  
   - Erasure Coding: You can use an $[S, S-F]$ code (where $S$ is your total number of storage providers). The overhead is $\frac{S}{S-F}$, which is generally less than $F+1$ for most practical values of $S$ and $F$.  

   | # Providers ($S$) | # Failures ($F$) | Replication Overhead | Erasure Code Overhead | Storage Savings |
   |-----------------|----------------|----------------------|-----------------------|-----------------|
   | 4               | 2              | 3X                   | 2X                    | 33%            |
   | 5               | 2              | 3X                   | 1.67X (approx)        | ~44%           |

- Enhanced Security  
   Because each shard is only a fragment, no single shard (fewer than $K$) reveals the original data. This is a built-in layer of “information slicing” that can augment your security posture.

---

# Mathematical Foundations

## Linear Algebra Primer

At the core of erasure coding lies matrix multiplication. We treat data chunks as vectors and multiply by an encoder matrix. Some key definitions:

- A vector $v$ in $\mathbb{R}^K$ is $\begin{bmatrix}v_1 \\ v_2 \\ \dots \\ v_K \end{bmatrix}$.  
- An $(N\times K)$ matrix $M$ is an array of $N$ rows and $K$ columns.  
- Matrix multiplication: $M \cdot v$ yields an $N\times 1$ vector.

For erasure coding, we construct a matrix $E$ (size $N\times K$). The encoded shards are simply:

$$
\text{encoded} = E \times \text{datavector}.
$$

## Cauchy Matrices: Guaranteed Invertibility

To be more precise, not just any matrix works. We need that *any* $K \times K$ submatrix is invertible over our chosen field. [Cauchy matrices](https://en.wikipedia.org/wiki/Cauchy_matrix) are a classic choice:

$$
C_{i,j} = \frac{1}{x_i - y_j}, \quad 1 \leq i \leq N,\ 1 \leq j \leq K,
$$

where $\{x_1, \dots, x_N\}$ and $\{y_1, \dots, y_K\}$ are all distinct elements in a field.

- Construction  
   - Pick $N$ distinct values $\{x_1, \dots, x_N\}$.  
   - Pick $K$ distinct values $\{y_1, \dots, y_K\}$ that don’t overlap with the $x_i$.  
   - Fill the matrix with $\frac{1}{x_i - y_j}$.  

- Why submatrices are invertible  
   Each $K\times K$ submatrix is also a Cauchy matrix (just a “smaller slice” of the bigger one). The determinant of a Cauchy matrix has a known closed-form that is *never zero* if the $x_i$ and $y_j$ sets are distinct.

## Encoding/Decoding Example in Simple Terms

Suppose $K=2$, $N=3$. Let $\{x\}=\{1,2,4\}$, $\{y\}=\{0,3\}$. Then,

$$
E =
\begin{bmatrix}
\frac{1}{1-0} & \frac{1}{1-3} \\
\frac{1}{2-0} & \frac{1}{2-3} \\
\frac{1}{4-0} & \frac{1}{4-3}
\end{bmatrix}
=
\begin{bmatrix}
1 & -\tfrac{1}{2} \\
\tfrac{1}{2} & -1 \\
\tfrac{1}{4} & 1
\end{bmatrix}.
$$

> Real caution: We’ll ultimately do all arithmetic in a *finite field* to avoid floating-point issues. But this matrix illustrates the structure.

- Encoding:  
   $$
   \begin{bmatrix} \text{Shard 1}\\ \text{Shard 2}\\ \text{Shard 3}\end{bmatrix}
   =
   E
   \times
   \begin{bmatrix} d_1 \\ d_2 \end{bmatrix}.
   $$

- Decoding: If we only have shards 1 and 3, we form the $2\times2$ submatrix of $E$ from rows 1 and 3, invert it, then multiply by $\begin{bmatrix}\text{Shard 1}\\ \text{Shard 3}\end{bmatrix}$ to get $\begin{bmatrix} d_1 \\ d_2 \end{bmatrix}$.

---

# Finite Fields for Lossless Encoding

The above fractions $\tfrac{1}{2}, \tfrac{1}{4}, \dots$ in real arithmetic can cause precision issues in actual digital systems. Finite fields solve this by making every number an element of a set with *exact* modular arithmetic.

## Prime Fields $GF(p)$

- Elements: $\{0, 1, 2, \dots, p-1\}$.  
- Addition and multiplication are done $\mod p$.  
- Inverse: an element $a\neq0$ always has a multiplicative inverse $a^{-1}$ such that $(a \times a^{-1}) \equiv 1\ (\mod p)$.

### Example in $GF(7)$

Arithmetic Table for $GF(7)$ (Addition and Multiplication):

Addition ($mod \space 7$):

| +  | 0 | 1 | 2 | 3 | 4 | 5 | 6 |
|----|---|---|---|---|---|---|---|
| 0  | 0 | 1 | 2 | 3 | 4 | 5 | 6 |
| 1  | 1 | 2 | 3 | 4 | 5 | 6 | 0 |
| 2  | 2 | 3 | 4 | 5 | 6 | 0 | 1 |
| 3  | 3 | 4 | 5 | 6 | 0 | 1 | 2 |
| 4  | 4 | 5 | 6 | 0 | 1 | 2 | 3 |
| 5  | 5 | 6 | 0 | 1 | 2 | 3 | 4 |
| 6  | 6 | 0 | 1 | 2 | 3 | 4 | 5 |

Multiplication ($mod \space 7$):

| ×  | 0 | 1 | 2 | 3 | 4 | 5 | 6 |
|----|---|---|---|---|---|---|---|
| 0  | 0 | 0 | 0 | 0 | 0 | 0 | 0 |
| 1  | 0 | 1 | 2 | 3 | 4 | 5 | 6 |
| 2  | 0 | 2 | 4 | 6 | 1 | 3 | 5 |
| 3  | 0 | 3 | 6 | 2 | 5 | 1 | 4 |
| 4  | 0 | 4 | 1 | 5 | 2 | 6 | 3 |
| 5  | 0 | 5 | 3 | 1 | 6 | 4 | 2 |
| 6  | 0 | 6 | 5 | 4 | 3 | 2 | 1 |

Example: $\tfrac{1}{2} \equiv 4\ (\mod 7)$ because $2 \times 4 = 8 \equiv 1\ (\mod 7)$.

## Extension Fields $GF(2^n)$

Prime fields $GF(p)$ are great for small alphabets or numeric data. However, most real-world data is binary. $GF(2^n)$ (e.g., $GF(8)$, $GF(16)$, $GF(256)$, etc.) is often more natural:

- Elements can be seen as *polynomials* of $degree < n$, with coefficients in $\{0,1\}$.  
- Arithmetic is done modulo an irreducible polynomial of degree $n$.  
- Addition is bitwise XOR.  

### Example in $GF(8) = GF(2^3)$

Let the irreducible polynomial be $y^3 + y + 1$. Then each element is a 3-bit pattern: $000$, $001$, $010$, …, $111$.  

- Addition: $\oplus$ (XOR) on the bit pattern.  
- Multiplication: Multiply the polynomials, then reduce modulo $y^3 + y + 1$.

### Concrete Example of Multiplication in $GF(8)$

Suppose we label $\alpha = y$ (the polynomial representing $010$ in binary). Then:

$$
\alpha^3 = \alpha \times \alpha^2 = (y) \times (y^2) = y^3 \equiv y + 1 \quad (\text{mod } y^3 + y + 1),
$$

hence $\alpha^3 = \alpha + 1$. This identity helps compute higher powers.

Let’s do a direct multiplication:

$$
(y^2 + y + 1) \times (y^2 + 1)\quad \text{mod } (y^3 + y +1).
$$

- Polynomial multiplication:  
   $$
   (y^2 \cdot y^2) + (y^2 \cdot 1) + (y \cdot y^2) + (y \cdot 1) + (1 \cdot y^2) + (1 \cdot 1)
   $$
   $$
   = y^4 + y^2 + y^3 + y + y^2 + 1
   $$
   $$
   = y^4 + y^3 + 2y^2 + y + 1.
   $$

- Because we’re in $GF(2^3)$, note $2y^2 = 0$ (coefficient 2 in binary is 0), so we get:  
   $$
   y^4 + y^3 + y + 1.
   $$

- Now reduce mod $y^3 + y +1$:  
   - $y^4 = y \cdot y^3 = y (y+1) = y^2 + y.$  
   So the expression becomes:  
   $$
   (y^2 + y) + y^3 + y + 1.
   $$
   Combine like terms (remember additions are XOR, so repeated terms vanish):  
   $$
   y^2 + y^3 + 1 = y^2 + y + 1 + 1 = y^2 + y.
   $$

This result, $\alpha^2 + \alpha$, is another polynomial in $GF(8)$. Tracking these steps carefully ensures exact, *lossless* arithmetic.

---

# Binary Matrices for Efficient Encoding

While $GF(2^n)$ arithmetic is conceptually clean, direct polynomial multiplication can be CPU-intensive for large data. A popular optimization is to represent each element of $GF(2^n)$ as an $n\times n$ binary matrix:

- Addition in $GF(2^n) \leftrightarrow$ XOR of the matrix bits.  
- Multiplication in $GF(2^n) \leftrightarrow$ a combination of matrix multiplication + XOR.  

Moreover, many real systems skip the explicit matrix representation and simply do repeated XOR operations in hardware. For example, if you only have coefficients $0$ or $1$, you can pick an encoding matrix with lots of $0/1$ patterns, so each row’s multiplication is basically:

$$
\text{shard} = \bigoplus_{\substack{\text{positions } j \\ \text{where row}[j]=1}} \text{datablock}_j,
$$

where $\oplus$ is XOR.

## How Can You Use Extension Fields To Encode Arbitrary Binary Data?

When storing or transmitting raw binary data, using a prime field like $GF(7)$ or $GF(11)$ can create a mismatch: each field element might correspond awkwardly to 2-bit or 3-bit chunks, wasting bits and inflating storage. Extension fields avoid this by letting each element directly represent $n$-bit strings, seamlessly aligning with binary data.

For instance, $GF(2^3)$ is an 8-element field that uses 3-bit representations ($000$ to $111$) and polynomial arithmetic modulo an irreducible polynomial of degree 3. Below, we’ll see:

- A reference table of $GF(2^3)$ elements  
- Basic arithmetic in $GF(2^3)$  
- An example of encoding “CCDCFE” with a $[3, 2]$ code—without the bit overhead of prime fields

### Elements of $GF(2^3)$

We pick an irreducible polynomial $y^3 + y + 1 = 0$. Label each of the 8 elements as a binary string $\{000, 001, 010, 011, 100, 101, 110, 111\}$. We can also view each element as a degree < 3 polynomial in $y$:

| Element # | Polynomial        | 3-bit Representation |
|-----------|-------------------|----------------------|
| 0         | $0y^2 + 0y + 0$ | `000`               |
| 1         | $0y^2 + 0y + 1$ | `001`               |
| 2         | $0y^2 + 1y + 0$ | `010`               |
| 3         | $0y^2 + 1y + 1$ | `011`               |
| 4         | $1y^2 + 0y + 0$ | `100`               |
| 5         | $1y^2 + 0y + 1$ | `101`               |
| 6         | $1y^2 + 1y + 0$ | `110`               |
| 7         | $1y^2 + 1y + 1$ | `111`               |



### Arithmetic in $GF(2^3)$

Now, lets understand how arithmetic operations work in $GF(2^3)$.

**Addition**
   - Performed as bitwise XOR on the 3-bit representation.  
   - Polynomial view: Coefficients are added modulo 2.  
   - Example: $6 + 7$ in binary is `110` $\oplus$ `111` = `001` (which is 1).

**Subtraction**
   - Same as addition in characteristic 2 (since each element is its own negative).  
   - Example: $6 - 6 = 110 \oplus 110 = 000 = 0$.

**Multiplication**
   - Multiply the polynomials, then reduce modulo $y^3 + y + 1$.  
   - Example: $6 \times 7$ means  
     
     $$
       (y^2 + y) \;\times\; (y^2 + y + 1)
       = (y^4 + y^3 + y^2) + (y^3 + y^2 + y)
       =(y^4 +  y) = y*(y^3 + 1) \\
       = y*(y + 1 + 1) = y*y = y^2
       \;\;\text{mod}\;\; (y^3 + y +1).
     $$
     
     After polynomial expansion and reduction, the result is $y^2$, which corresponds to `100` (element #4).

The multiplication table for $GF(2^3)$ might look like this:

| $*$ | `000` | `001` | `010` | `011` | `100` | `101` | `110` | `111` |
|---------|-------|-------|-------|-------|-------|-------|-------|-------|
| `000`   | `000` | `000` | `000` | `000` | `000` | `000` | `000` | `000` |
| `001`   | `000` | `001` | `010` | `011` | `100` | `101` | `110` | `111` |
| `010`   | `000` | `010` | `100` | `110` | `011` | `001` | `111` | `101` |
| `011`   | `000` | `011` | `110` | `101` | `111` | `100` | `001` | `010` |
| `100`   | `000` | `100` | `011` | `111` | `110` | `010` | `101` | `001` |
| `101`   | `000` | `101` | `001` | `100` | `010` | `111` | `011` | `110` |
| `110`   | `000` | `110` | `111` | `001` | `101` | `011` | `010` | `100` |
| `111`   | `000` | `111` | `101` | `010` | `001` | `110` | `100` | `011` |

**Division**

Division in $GF(2^n)$ can seem unusual at first. In general, division in $GF(2^n)$ is done by multiplying by the multiplicative inverse.

Let's see exactly how to compute:

$$
\frac{6}{7} \quad\text{in}\quad GF(2^3).
$$


**Step 1: Represent Numbers as Binary & Polynomials**

Let's map each number to its 3-bit binary string and then to the corresponding polynomial in $y$:

| Decimal | Binary | Polynomial       |
|---------|--------|------------------|
| 6   | `110`  | $y^2 + y$      |
| 7   | `111`  | $y^2 + y + 1$  |

Our goal is to compute, in $GF(2^3)$:

$$
\frac{6}{7} \;=\; 6 \;\times\; 7^{-1},
$$
where $7^{-1}$ is defined by $7 \times 7^{-1} = 1$.



**Step 2: Find the Inverse of 7 ($7^{-1}$)**

We test all non-zero elements to find $\alpha$ such that $7 \times \alpha = 1$.


Each product $7 \times \alpha$ is computed using polynomial multiplication modulo $y^3 + y + 1$ (the irreducible polynomial). Here’s how:

1. $7 \times 1$ (binary `001`)  
   $$
   (y^2 + y + 1) \times 1 = y^2 + y + 1 \quad (\text{= 7, binary `111`}).
   $$

2. $7 \times 2$ (binary `010` = $y$)  
   $$
   (y^2 + y + 1) \times y = y^3 + y^2 + y.
   $$  
   Reduce $y^3$ using $y^3 \equiv y + 1$:  
   $$
   (y + 1) + y^2 + y = y^2 + 1 \quad (\text{= 5, binary `101`}).
   $$

3. $7 \times 5$ (binary `101` = $y^2 + 1$)  
   $$
   (y^2 + y + 1)(y^2 + 1) = y^4 + y^3 + y^2 + y^2 + y + 1.
   $$  
   Simplify ($y^2 + y^2 = 0$) and reduce $y^4 = y^2 + y$, $y^3 = y + 1$:  
   $$
   (y^2 + y) + (y + 1) + y + 1 = 1 \quad (\text{= 1, binary `001`}).
   $$  
   This confirms $7^{-1} = 5$.

**Inverse Test Results**


| Candidate $\alpha$ | Compute $7 \times \alpha$ | Result |
|------------------------|--------------------------------|--------|
| `001` (1)              | 7                              | ≠ 1    |
| `010` (2)              | 5                              | ≠ 1    |
| `011` (3)              | 4                              | ≠ 1    |
| `100` (4)              | 6                              | ≠ 1    |
| **`101` (5)**          | **1**                          | **✅ = 1** |
| `110` (6)              | 2                              | ≠ 1    |
| `111` (7)              | 3                              | ≠ 1    |


**Step 3: Perform the Division $\,6 \div 7\,$**

Now compute:  
$$
6 \div 7 = 6 \times 5 = (y^2 + y)(y^2 + 1).
$$

**Polynomial Multiplication**
$$
(y^2 + y)(y^2 + 1) = y^4 + y^3 + y^2 + y.
$$

**Reduction Modulo $y^3 + y + 1$**
1. Substitute $y^4 = y^2 + y$ and $y^3 = y + 1$:  
   $$
   (y^2 + y) + (y + 1) + y^2 + y.
   $$  
2. Simplify (coefficients are mod 2):  
   $$
   \cancel{y^2} + \cancel{y} + \cancel{y} + 1 + \cancel{y^2} + y = y + 1 \quad (\text{= 3, binary `011`}).
   $$


Hence we get,
$$
\frac{6}{7} = 3 \quad \text{in} \quad GF(2^3).
$$  

*(Binary: `110 ÷ 111 = 011`)*



### Encoding Example: “CCDCFE” in a $[3, 2]$ Code over $GF(2^3)$

Suppose you’re erasure-coding the short melody “C, C, D, C, F, E” (each note mapped to numbers `2`, `2`, `3`, `2`, `5`, `4`) but now you want to avoid chunk inflation. You choose $GF(2^3)$, which handles 3-bit chunks directly—no wasted bits. Lets work out the encoding/decoding details.

#### Map Notes to $GF(2^3)$ Elements

We have the melody: C, C, D, C, F, E. Suppose we assign the following numeric representations:

- C → 2  
- D → 3  
- E → 4  
- F → 5  

These numbers are elements in $GF(2^3)$ if we interpret them in binary:

- 2 → `010`  (polynomial $y$)  
- 3 → `011`  ($y + 1$)  
- 4 → `100`  ($y^2$)  
- 5 → `101`  ($y^2 + 1$)

Hence, the sequence “CCDCFE” is: `[2, 2, 3, 2, 5, 4]`.

#### Block the Data (K=2)

For a $[3,2]$ Erasure code, each data block has size $K=2$. Break the 6-note sequence into 3 blocks:

1. Block 1: $[C, C]$ = $[2, 2]$  
2. Block 2: $[D, C]$ = $[3, 2]$  
3. Block 3: $[F, E]$ = $[5, 4]$

#### Choose an Encoder Matrix (N=3, K=2)



We need an $3 \times 2$ matrix $E$ in GF($2^3$) whose every $2 \times 2$ submatrix is invertible. That’s the key requirement for a successful $[3,2]$ erasure code: any 2 shards should suffice to reconstruct the 2 original data chunks.

A classic way, as noted above, is to build a Cauchy matrix by picking distinct $\{x_1,\dots,x_N\}$ and $\{y_1,\dots,y_K\}$ in our field and letting

$$
C_{i,j} = \frac{1}{x_i - y_j}.
$$

However, sometimes a matrix that is “Cauchy-like” or otherwise carefully chosen also works—so long as it meets the invertibility criteria. In this example, we use:

$$
E \;=\; 
\begin{bmatrix}
1 & 1\\
2 & 3\\
4 & 5
\end{bmatrix}
\quad \text{in } GF(2^3).
$$

Here’s why it’s valid:
- Distinct Elements: Each row has unique field elements (like `001`, `010`, `011`, `100`, `101` in binary).  
- Submatrix Invertibility: If you take *any* two rows (giving a $2\times2$ submatrix) and compute its determinant in GF($2^3$), you’ll get a non-zero result—meaning it’s invertible.  

> *In practice, you can verify submatrix invertibility by calculating each pair’s determinant via finite-field arithmetic. This step is typically done offline or via code, ensuring you have a guaranteed invertible matrix without having to rely strictly on the $\frac{1}{x_i - y_j}$ formula.*

Thus, while you can explicitly construct a matrix using the formal Cauchy definition, it’s enough to ensure all $2\times2$ minors are invertible. Our example $\begin{bmatrix}1 & 1\\2 & 3\\4 & 5\end{bmatrix}$ meets that condition, so it serves as a valid $[3,2]$ encoder.


Hence, we can use:

$$
E \;=\; 
\begin{bmatrix}
1 & 1\\
2 & 3\\
4 & 5
\end{bmatrix},
$$
where each entry is an element in $GF(2^3)$. In binary/polynomial form:

- $1$ is `001` ($y^0$)  
- $2$ is `010` ($y$)  
- $3$ is `011` ($y + 1$)  
- $4$ is `100` ($y^2$)  
- $5$ is `101` ($y^2 + 1$)

#### Encode Each Block

To encode a block $\begin{bmatrix} x \\ y \end{bmatrix}$, we compute:

$$
\begin{bmatrix}
\text{Shard}_1\\
\text{Shard}_2\\
\text{Shard}_3
\end{bmatrix}
= 
E \times
\begin{bmatrix} x\\ y\end{bmatrix}.
$$

That yields 3 output shards for each block. Let’s do each block in detail:

**Block 1: [2, 2]**

- Data vector: $[2, 2]$ 
- Multiply:

- Shard 1 = $[1, 1] \cdot [2, 2]$  
   - In $GF(2^3)$, addition is XOR, so $(1\times2) \oplus (1\times2)$.  
   - $1\times 2 = 2$. Then $2 \oplus 2 = 0$. So Shard 1 = `000`.

- Shard 2 = $[2, 3] \cdot [2, 2]$  
   - $2 \times 2 = y \times y = y^2 = 4$ in decimal (`100`).  
   - $3 \times 2 =$ ( $y+1$ ) $\times y = y^2 + y =$ `110` = 6.  
   - Then XOR them: $4 \oplus 6 =$ `100` $\oplus$ `110` = `010` = 2.  
   - So Shard 2 = `010` (decimal 2).

- Shard 3 = $[4, 5] \cdot [2,2]$  
   - $4 \times 2 = (y^2)\times(y) = y^3$.  
     Since $y^3 = y + 1$ in our irreducible polynomial, that’s `011` = 3.  
   - $5 \times 2 =$ ( $y^2 + 1$ ) $\times y = y^3 + y$.  
     - $y^3 = y + 1$, so $y^3 + y = (y+1) \oplus y = 1$.  
     - That’s `001` in binary, decimal 1.  
   - XOR them: $3 \oplus 1 =$ `011` $\oplus$ `001` = `010` = 2.  
   - So Shard 3 = `010` (decimal 2).

Thus, Block 1 encodes to Shard vector = $[0,\; 2,\; 2]$.

**Block 2: [3, 2]**

- Data vector: $[3, 2]$  
- Multiply:

- Shard 1 = $[1, 1] \cdot [3, 2]$  
   - $1 \times 3 \oplus 1 \times 2 = 3 \oplus 2 =$ `011` $\oplus$ `010` = `001` = 1.  

- Shard 2 = $[2, 3] \cdot [3, 2]$  
   - $2 \times 3 = (y)\times(y+1)$. That’s $y^2 + y$, or `110` = 6.  
   - $3 \times 2 = (y+1)\times y$. Same as above, also `110` = 6.  
   - XOR them: `110` $\oplus$ `110` = `000` = 0.  

- Shard 3 = $[4, 5] \cdot [3, 2]$  
   - $4 \times 3 = (y^2)\times(y+1) = y^3 + y^2$.  
     - $y^3 = (y+1)$, so $y^3 + y^2 = (y+1) \oplus (y^2)$. That’s `011` $\oplus$ `100` = `111` = 7.  
   - $5 \times 2 =$ ( $y^2+1$ ) $\times y = y^3 + y = 1$, as seen earlier.  
   - XOR them: `111` $\oplus$ `001` = `110` = 6.  

Hence, Block 2 → $[1, 0, 6]$ in decimal, i.e. `[001, 000, 110]` in binary.


**Block 3: [5, 4]**

- Data vector: $[5, 4]$  
- Multiply:

- Shard 1 = $[1,1]\cdot [5,4]$  
   - $5 \oplus 4 =$ `101` $\oplus$ `100` = `001` = 1.  

- Shard 2 = $[2,3]\cdot [5,4]$  
   - $2 \times 5 = (y)\times(y^2+1) = y^3 + y = 1$ (as above).  
   - $3 \times 4 = (y+1)\times (y^2)$.  
     - That’s $y^3 + y^2$. With $y^3 = y + 1$, we get $(y+1) \oplus y^2 =$ `011` $\oplus$ `100` = `111`= 7.  
   - XOR them: `001` $\oplus$ `111` = `110` = 6.  

- Shard 3 = $[4,5]\cdot [5,4]$  
   - $4 \times 5 = (y^2)\times (y^2+1) = y^4 + y^2.$  
     - $y^4 = y \times y^3 = y(y+1)= y^2 + y$. So $y^4 + y^2 = (y^2+y)\oplus y^2 = y$.  
     - So that’s `010` = 2 in decimal.  
   - $5 \times 4 = (y^2+1)\times(y^2) = y^4 + y^2$. Same expansion, also `010` = 2.  
   - XOR them: 2 $\oplus$ 2 = 0.  

Hence, Block 3 → $[1,6,0]$.


#### Final Encoded Shards

Putting it all together, the encoded shards for each block (in decimal) look like:

- Block 1 = $\bigl[0,\; 2,\; 2\bigr]$  
- Block 2 = $\bigl[1,\; 0,\; 6\bigr]$  
- Block 3 = $\bigl[1,\; 6,\; 0\bigr]$

In binary (3-bit each):

- Block 1 shards = `[000, 010, 010]`  
- Block 2 shards = `[001, 000, 110]`  
- Block 3 shards = `[001, 110, 000]`

Each row is stored in a separate code shard (Shard 1, Shard 2, Shard 3). If any single shard fails, you can decode from the remaining two.

#### Decoding an Example

Suppose in Block 2 we lose Shard 2 but keep Shard 1 and Shard 3:

- Known: 
   - Shard 1 = `001` (decimal 1)  
   - Shard 3 = `110` (decimal 6)  
- Corresponding Rows: Rows #1 and #3 in $E$:

   $$
   E' = 
   \begin{bmatrix}
   1 & 1 \\
   4 & 5
   \end{bmatrix}
   \ (\text{in GF}(2^3)).
   $$

- Inverse $E'$:  
   - We compute $\det(E')$ and do the usual polynomial-based inverse in $GF(2^3)$. (Omitted for brevity, but it’s a standard procedure using polynomial arithmetic or a small lookup table.)  

- Recover Original $\begin{bmatrix}x\\ y\end{bmatrix}$ = $(E')^{-1} \cdot [\text{Shard1}, \text{Shard3}]^T$.  

You’d find $[3, 2]$ emerges, confirming the data block `[3,2]` (D, C).

This approach aligns perfectly with the binary data. No “unused permutations” or partial bits are wasted—every possible 3-bit string is a valid element.

---

# Practical Implementation

## Algorithmic Pseudocode

```mermaid
sequenceDiagram
    participant U as User Data
    participant S as Shards in Cloud/Storage
    participant E as Encoder/Decoder
    U ->> E: Provide data block(s)
    E ->> E: Encode (Matrix Mult in GF(2^n))
    E ->> S: Distribute N shards
    Note over S: Some shards lost/fail
    S ->> E: Provide any K remaining shards
    E ->> E: Decode (Submatrix Inversion)
    E ->> U: Return original data
```


Let’s illustrate a simplified $[4, 2]$ code in $GF(8)$. We’ll show how each step ties to the mathematics:

Encoder Construction (Cauchy-like or custom-designed):
```plaintext
Given irreducible polynomial p(y) for GF(8),
Define encoder_matrix E of size (4 x 2), with each entry in GF(8).

Example (not necessarily minimal):
E = [
  [1, 1],  # row 0
  [2, 3],  # row 1
  [4, 5],  # row 2
  [6, 7]   # row 3
]
```

Encoding:
```plaintext
function encode_block(data_vector):
    # data_vector has length 2 in GF(8)
    # encoder_matrix E is 4 x 2

    shards = E * data_vector   # matrix multiply in GF(8)
    return shards  # length 4
```

Decoding:
```plaintext
function decode_shards(shards_subset, row_indices):
    # shards_subset has length K=2 (any 2 shards from the 4)
    # row_indices is which rows of E they came from (e.g., [0,2])

    E_sub = submatrix(E, row_indices)  # shape 2 x 2
    E_sub_inv = invert(E_sub in GF(8)) # find matrix inverse in GF(8)

    data_vector = E_sub_inv * shards_subset
    return data_vector
```

## Step-by-Step Example with $GF(7)$

Below, we do an explicit example with $GF(7)$. Let’s say:

- $K = 2, N = 3$.  
- Data vector = $[2, 2]$ in $GF(7)$.  
- Encoder matrix:

$$
E=
\begin{bmatrix}
\frac{1}{2} & 1 \\
\frac{1}{3} & \frac{1}{2} \\
\frac{1}{4} & \frac{1}{3}
\end{bmatrix} \quad (\text{all ops mod }7).
$$

We interpret $\frac{1}{2}\equiv4$, $\frac{1}{3}\equiv5$, $\frac{1}{4}\equiv2$ in $GF(7)$. So:

$$
E =
\begin{bmatrix}
4 & 1 \\
5 & 4 \\
2 & 5
\end{bmatrix} \ (\mod 7).
$$

- Encoding:

$$
\begin{bmatrix} \text{Shard1}\\ \text{Shard2}\\ \text{Shard3}\end{bmatrix}
=
\begin{bmatrix}
4 & 1 \\
5 & 4 \\
2 & 5
\end{bmatrix}
\cdot
\begin{bmatrix}2\\2\end{bmatrix}
=
\begin{bmatrix}
(4\times2 + 1\times2)\mod7\\
(5\times2 + 4\times2)\mod7\\
(2\times2 + 5\times2)\mod7
\end{bmatrix}.
$$

That is:

- Shard1 = $(8 + 2)\mod7 = 10 \mod7 = 3$.  
- Shard2 = $(10 + 8)\mod7 = 18 \mod7 = 4$.  
- Shard3 = $(4 + 10)\mod7 = 14 \mod7 = 0$.

Hence, $\text{shards}=[3,4,0]$.

- Decoding (suppose we only have shards 1 and 3). Then $\text{shards\_subset}=[3, 0]$ from rows [0, 2] in $E$. The submatrix is:

$$
E'=
\begin{bmatrix}
4 & 1\\
2 & 5
\end{bmatrix}.
$$

Compute its inverse in $GF(7)$. The determinant $\Delta = 4\times5 - 1\times2 = 20 - 2 = 18 \equiv 4 \ (\mod7)$. The inverse of $\Delta=4$ is $2$, because $4\times2=8\equiv1\ (\mod7)$.

The inverse matrix is:

$$
(E')^{-1} = \frac{1}{\Delta}
\begin{bmatrix}
5 & -1 \\
-2 & 4
\end{bmatrix}
=
2 \times
\begin{bmatrix}
5 & 6 \\  
5 & 4    
\end{bmatrix}
=
\begin{bmatrix}
10 & 12\\
10 & 8
\end{bmatrix}
\mod7
=
\begin{bmatrix}
3 & 5\\
3 & 1
\end{bmatrix}.
$$

Now multiply $(E')^{-1}\times[3,0]^T$:

$$
\begin{bmatrix}
3 & 5\\
3 & 1
\end{bmatrix}
\cdot
\begin{bmatrix}
3\\
0
\end{bmatrix}
=
\begin{bmatrix}
(3\times3 + 5\times0)\mod7\\
(3\times3 + 1\times0)\mod7
\end{bmatrix}
=
\begin{bmatrix}
9\mod7\\
9\mod7
\end{bmatrix}
=
\begin{bmatrix}
2\\
2
\end{bmatrix}.
$$

We recover 

$$\begin{bmatrix}2\\
2\end{bmatrix}$$ 

exactly—our original data vector.

---

# Challenges and Beyond

- Repair Overhead:  
   When a shard is lost, you can regenerate it by decoding from any $K$ surviving shards and re-encoding. This can be bandwidth-heavy. Advanced solutions (e.g., Local Reconstruction Codes) mitigate this by adding local parity shards.

- Quantum Threats:  
   Erasure coding itself is not threatened by quantum computing (it’s linear algebra). However, cryptographic layers that often run *on top* must adapt to post-quantum methods.

- Implementation Complexity:  
   - Coordinating multiple cloud providers or physical disks.  
   - Tracking lost shards and orchestrating repairs.  
   - Ensuring code correctness with finite-field arithmetic—bugs can be subtle.

---


>I wrote about how Erasure coding works in Ethereum Danksharding using Reed Solomon Codes. You can read this [here.](https://thogiti.github.io/2023/11/09/Error-Correction-in-Danksharding-Harnessing-the-Power-of-Generalized-Reed-Solomon-Codes-for-Ethereum-Scalability.html)

# Conclusion

Erasure coding bridges abstract linear algebra and practical data reliability. By splitting data into shards, we gain:

- Durability: Tolerate multiple failures with less overhead than replication.  
- Security: No single shard reveals the entire file.  
- Efficiency: Fine-tuned overhead, especially when scaling storage.  

As data volumes skyrocket, erasure coding becomes a must-have. With the knowledge of finite-field arithmetic and matrix mechanics, you’re ready to implement or optimize an erasure-coding system. Embrace it now to keep your data safe from unexpected storage failures—and do so *cost-effectively*.

---

# Appendix & Further Reading

- Full $GF(2^n)$ Implementation Examples: Libraries like [galois (Python)](https://pypi.org/project/galois/) and [Intel ISA-L Erasure Coding (C)](https://github.com/intel/isa-l) offer production-grade building blocks.  
- [Cachy matrices.](https://en.wikipedia.org/wiki/Cauchy_matrix)
- [Local reconstruction codes.](https://www.usenix.org/system/files/conference/atc12/atc12-final181_0.pdf)
- [Hamming codes - the origin of error correction part 1 by 3blue1brown.](https://www.youtube.com/watch?v=X8jsijhllIA)
- [Hamming codes - the origin of error correction part 2 by 3blue1brown.](https://www.youtube.com/watch?v=b3NxrZOu_CE)
- [Error Correction in Ethereum's Danksharding - Harnessing the Power of Generalized Reed-Solomon Codes for Ethereum's Scalability](https://thogiti.github.io/2023/11/09/Error-Correction-in-Danksharding-Harnessing-the-Power-of-Generalized-Reed-Solomon-Codes-for-Ethereum-Scalability.html)